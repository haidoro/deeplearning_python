# Pythonで学ぶDeep Learning

## パーセプトロン
パーセプトロンとはニューラルネットワークを学習する上でその起源となるものです。パーセプトロンを理解することは機械学習を勉強する上で重要な入り口となるでしょう。
そして神経細胞の仕組みをアルゴリズムに取り入れたのがパーセプトロン（人口ニューロン）です。

詳細は[Pythonの勧め（4）パーセプトロンについて](https://itstudio.co/2018/03/04/7544/)を参照

ここではANDゲート、NANDゲート、ORゲート、XORゲートを関数化しています。引数の値は1か0として結果がどうなるか確認します。

XORゲートは単独ではうまく行きません。この場合はXORゲートのみ単独では実現できません。その場合はNANDとORゲートの出力をANDゲートの入力にすることで解決します。

## ニューラルネットワーク
パーセプトロンは人間が重みのパラメータを設定していたが、コンピュータにそれをやらせたい。  
そこで登場したのがニューラルネットワークになります。

もっとも単純なニューラルネットワークは入力層、中間層、出力層でできています。

中間層が重みやバイアスを自動化することができます。
特に、逆伝播による方法で精度が大幅に向上しました。

## 活性化関数について

### ステップ関数

パーセプトロンの例でANDゲートの場合次のような処理を行いました。
```
if tmp <= 0:
        return 0
    else:
        return 1
```

これは単純に`tmp = np.sum(w*x) + b`だけでは1か0の値を導けないためです。  
そしてこの処理を関数化したものを***活性化関数***と呼びます。

例えば次のような関数で表します。

```
def step_function(x):
    return np.array(x > 0,dtype=np.int)
```

この関数を実際に活用してグラフ描画したものが、perceptronコードにある「ステップ関数とグラフ」になります。

```
import numpy as np
import matplotlib.pylab as plt
%matplotlib inline

def step_function(x):
    return np.array(x > 0,dtype=np.int)

x = np.arange(-5.0,5.0,0.1)
y = step_function(x)
plt.plot(x,y)
plt.ylim(-0.1,1.1)
plt.show()
```

このグラフは見ての通り特徴のあるものでその形態からステップ関数と言われています。

### シグモイド関数

そしてニューラルネットワークでの活性化関数はシグモイド関数と呼ばれるものです。

ネイピア数を活用したもので`1 / (1 + np.exp(-x))`で記述することができます。

```
def sigmoid(x):
    return 1 / (1 + np.exp(-x))
    
x = np.arange(-5.0,5.0,0.1)
y = sigmoid(x)
plt.plot(x,y)
plt.ylim(-0.1,1,1.1)
plt.show()
```









